name: Alfresco Identity Service CI

on:
  push:
    branches:
      - master
      - AUTH-**
      - OPSEXP-**
      - feature/**
      - fix/**
  workflow_dispatch:
  schedule:
    - cron: "0 5 * * 3"

env:
  S3_ARTIFACTS_BUCKET: ${{ secrets.S3_ARTIFACTS_BUCKET }}
  S3_STAGING_BUCKET: alfresco-artefacts-staging
  S3_RELEASE_BUCKET: ${{ secrets.S3_RELEASE_BUCKET }}
  AUTH0_CLIENT_ID: ${{ secrets.AUTH0_CLIENT_ID }}
  AUTH0_CLIENT_SECRET: ${{ secrets.AUTH0_CLIENT_SECRET }}
  MAVEN_USERNAME: ${{ secrets.NEXUS_USERNAME }}
  MAVEN_PASSWORD: ${{ secrets.NEXUS_PASSWORD }}
  GITHUB_TOKEN: ${{ secrets.BOT_GITHUB_TOKEN }}
  HELM_REPO_BASE_URL: https://kubernetes-charts.alfresco.com
  HELM_REPO: incubator
  HELM_DOCS_VERSION: 1.11.0
  AWS_REGION: eu-west-1
  PROJECT_NAME: alfresco-identity-service

jobs:
  pre-commit:
    name: "Pre-commit"
    runs-on: ubuntu-latest
    steps:
      - name: "Install helm-docs"
        run: |
          curl -fsSL https://github.com/norwoodj/helm-docs/releases/download/v$HELM_DOCS_VERSION/helm-docs_${HELM_DOCS_VERSION}_$(uname)_x86_64.tar.gz | sudo tar xz -C /usr/local/bin/ helm-docs
          helm-docs --version
      - uses: Alfresco/alfresco-build-tools/.github/actions/pre-commit@v1.34.2

  build:
    name: "Build"
    runs-on: ubuntu-latest
    needs: pre-commit
    steps:
      - uses: actions/checkout@v3
      - uses: Alfresco/alfresco-build-tools/.github/actions/get-build-info@v1.34.2
      - uses: Alfresco/alfresco-build-tools/.github/actions/setup-java-build@v1.34.2
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_PIPELINE_AMPS_ACCESS_KEY_ID  }}
          aws-secret-access-key: ${{ secrets.AWS_S3_PIPELINE_AMPS_SECRET_ACCESS_KEY  }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Build"
        id: build
        run: |
          source distribution/build.properties
          export IDENTITY_VERSION=${IDENTITY_VERSION}
          echo "IDENTITY_VERSION=${IDENTITY_VERSION}"
          # build and package
          cd distribution
          make || { echo "Command failed with error code $?"; sleep 1; exit 1; }
          # upload ZIP file to S3 bucket
          aws s3 cp alfresco-identity-service-${IDENTITY_VERSION}.md5 s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/
          aws s3 cp alfresco-identity-service-${IDENTITY_VERSION}.zip s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/
      - name: "Clean up S3 after failure"
        if: ${{ always() && steps.build.outcome == 'failure' }}
        run: aws s3 rm s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/ --recursive

  test_linux:
    name: "Test on Linux"
    runs-on: ubuntu-latest
    needs: build
    if: ${{ !contains(github.event.head_commit.message, '[skip tests]') }}
    steps:
      - uses: actions/checkout@v3
      - uses: Alfresco/alfresco-build-tools/.github/actions/get-build-info@v1.34.2
      - uses: Alfresco/alfresco-build-tools/.github/actions/setup-java-build@v1.34.2
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_PIPELINE_AMPS_ACCESS_KEY_ID  }}
          aws-secret-access-key: ${{ secrets.AWS_S3_PIPELINE_AMPS_SECRET_ACCESS_KEY  }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Test"
        id: test
        run: |
          source distribution/build.properties
          export IDENTITY_VERSION=${IDENTITY_VERSION}
          echo "IDENTITY_VERSION=${IDENTITY_VERSION}"
          aws s3 cp s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/alfresco-identity-service-${IDENTITY_VERSION}.zip .
          ./distribution/tests/endpoints.sh
      - name: "Clean up S3 after failure"
        if: ${{ always() && steps.test.outcome == 'failure' }}
        run: aws s3 rm s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/ --recursive

  test_windows:
    name: "Test on Windows"
    runs-on: windows-latest
    needs: build
    if: ${{ !contains(github.event.head_commit.message, '[skip tests]') }}
    steps:
      - uses: actions/checkout@v3
      - uses: Alfresco/alfresco-build-tools/.github/actions/setup-java-build@v1.34.2
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_PIPELINE_AMPS_ACCESS_KEY_ID  }}
          aws-secret-access-key: ${{ secrets.AWS_S3_PIPELINE_AMPS_SECRET_ACCESS_KEY  }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Get BUILD_NUMBER"
        run: |
          echo "BUILD_NUMBER=$env:GITHUB_RUN_NUMBER" | Out-File -FilePath $env:GITHUB_ENV -Append
          echo $env:GITHUB_RUN_NUMBER
      - name: "Test"
        id: test
        run: |
          $Props = convertfrom-stringdata (get-content ./distribution/build.properties -raw)
          $env:IDENTITY_VERSION = $Props.'IDENTITY_VERSION'
          echo "IDENTITY_VERSION=$env:IDENTITY_VERSION"
          aws s3 ls s3://$env:S3_ARTIFACTS_BUCKET/ci-$env:BUILD_NUMBER/
          aws s3 cp s3://$env:S3_ARTIFACTS_BUCKET/ci-$env:BUILD_NUMBER/alfresco-identity-service-$env:IDENTITY_VERSION.zip .
          unzip alfresco-identity-service-$env:IDENTITY_VERSION.zip
          cd alfresco-identity-service-$env:IDENTITY_VERSION/bin
          powershell -Command Get-ExecutionPolicy
          powershell -Command 'Set-ExecutionPolicy unrestricted'
          powershell -Command $env:GITHUB_WORKSPACE/distribution/tests/endpoints_ps.ps1
          powershell -Command $env:GITHUB_WORKSPACE/distribution/tests/endpoints_bat.ps1
      - name: "Clean up S3 after failure"
        if: ${{ always() && steps.test.outcome == 'failure' }}
        run: aws s3 rm s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/ --recursive

  test_helm:
    name: "Test Helm Chart"
    runs-on: ubuntu-latest
    needs: build
    if: ${{ !contains(github.event.head_commit.message, '[skip tests]') }}
    steps:
      - uses: actions/checkout@v3
      - uses: Alfresco/alfresco-build-tools/.github/actions/get-build-info@v1.34.2
      - uses: Alfresco/alfresco-build-tools/.github/actions/setup-java-build@v1.34.2
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_PIPELINE_AMPS_ACCESS_KEY_ID  }}
          aws-secret-access-key: ${{ secrets.AWS_S3_PIPELINE_AMPS_SECRET_ACCESS_KEY  }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Prepare test environment"
        run: |
          openssl aes-256-cbc -K ${{ secrets.ENCRYPTED_E69BEC42AE64_KEY }} -iv ${{ secrets.ENCRYPTED_E69BEC42AE64_IV }} -in test/scripts/config-files/realmRsaKeys.json.enc -out test/scripts/config-files/realmRsaKeys.json -d
          aws eks update-kubeconfig --name acs-cluster
      - name: "Set IDS_BUILD_NAME"
        run: |
          IDS_BUILD_NAME=$(echo ${BRANCH_NAME} | cut -c1-28 | tr /_ - | tr -d [:punct:] | awk '{print tolower($0)}')-${BUILD_NUMBER}
          echo "IDS_BUILD_NAME=$IDS_BUILD_NAME" >> "$GITHUB_ENV"
          echo $IDS_BUILD_NAME
      - name: "Test"
        id: test
        run: |
          export namespace=${IDS_BUILD_NAME}
          export domain=dev.envalfresco.com
          export HOST=$namespace.$domain
          export release_name_ingress=ing-${BUILD_NUMBER}
          export release_name_ids=ids-${BUILD_NUMBER}
          export openldap_release=openldap-${BUILD_NUMBER}

          # Utility Functions

          # pod status
          pod_status() {
            kubectl get pods --namespace $namespace -o=custom-columns=NAME:.metadata.name,STATUS:.status.phase,READY:.status.conditions[?\(@.type==\'Ready\'\)].status
          }

          # pods ready
          pods_ready() {
            PODS_COUNTER=0
            PODS_COUNTER_MAX=60
            PODS_SLEEP_SECONDS=10

            while [ "$PODS_COUNTER" -lt "$PODS_COUNTER_MAX" ]; do
              totalpods=$(pod_status | grep -v NAME | wc -l | sed 's/ *//')
              readypodcount=$(pod_status | grep ' True' | wc -l | sed 's/ *//')
              if [ "$readypodcount" -eq "$totalpods" ]; then
                    echo "     $readypodcount/$totalpods pods ready now"
                    pod_status
                echo "All pods are ready!"
                break
              fi
                PODS_COUNTER=$((PODS_COUNTER + 1))
                echo "just $readypodcount/$totalpods pods ready now - sleeping $PODS_SLEEP_SECONDS seconds - counter $PODS_COUNTER"
                sleep "$PODS_SLEEP_SECONDS"
                continue
              done

            if [ "$PODS_COUNTER" -ge "$PODS_COUNTER_MAX" ]; then
              pod_status
              echo "Pods did not start - exit 1"
              exit 1
            fi
          }

          cat <<EOF | kubectl apply -f -
          apiVersion: v1
          kind: Namespace
          metadata:
            name: $namespace
          ---
          apiVersion: rbac.authorization.k8s.io/v1
          kind: Role
          metadata:
            name: $namespace:psp
            namespace: $namespace
          rules:
          - apiGroups:
            - policy
            resourceNames:
            - kube-system
            resources:
            - podsecuritypolicies
            verbs:
            - use
          ---
          apiVersion: rbac.authorization.k8s.io/v1
          kind: RoleBinding
          metadata:
            name: $namespace:psp:default
            namespace: $namespace
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: Role
            name: $namespace:psp
          subjects:
          - kind: ServiceAccount
            name: default
            namespace: $namespace
          ---
          apiVersion: rbac.authorization.k8s.io/v1
          kind: RoleBinding
          metadata:
            name: $namespace:psp:$release_name_ingress-nginx-ingress
            namespace: $namespace
          roleRef:
            apiGroup: rbac.authorization.k8s.io
            kind: Role
            name: $namespace:psp
          subjects:
          - kind: ServiceAccount
            name: $release_name_ingress-nginx-ingress
            namespace: $namespace
          ---
          $(kubectl create secret docker-registry quay-registry-secret --dry-run=client --docker-server=quay.io --docker-username=${{ secrets.QUAY_USERNAME }} --docker-password=${{ secrets.QUAY_PASSWORD }} -n $namespace -o yaml)
          EOF

          cat << EOR >> ingressvalues.yaml
          rbac:
            create: true
          controller:
            scope:
              enable: true
              namespace: $namespace
            admissionWebhooks:
              enabled: false
            config:
              proxy-body-size: "100m"
              generate-request-id: "true"
              PROXY-READ-TIMEOUT: "3600"
              proxy-send-timeout: "3600"
              ssl-redirect: "false"
              server-tokens: "false"
              use-forwarded-headers: "true"
            publishService:
              enabled: true
            service:
              targetPorts:
                https: http
                http: http
              annotations:
                external-dns.alpha.kubernetes.io/hostname: "$HOST"
                service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags: "Creator=Platform-Services,Department=Engineering,NoAutomaticShutdown=True,Owner=Platform-Services,Production=False,Purpose=DBP and SSO Testing,Tool=k8sIngress"
                service.beta.kubernetes.io/aws-load-balancer-backend-protocol: "http"
                service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: '3600'
                service.beta.kubernetes.io/aws-load-balancer-ssl-cert: ${{ secrets.ACM_CERTIFICATE }}
                service.beta.kubernetes.io/aws-load-balancer-ssl-ports: https
                service.beta.kubernetes.io/aws-load-balancer-ssl-negotiation-policy: ELBSecurityPolicy-TLS-1-2-2017-01
                service.beta.kubernetes.io/aws-load-balancer-security-groups: ${{ secrets.AWS_SECURITY_GROUP }}
          EOR

          # install ingress-nginx
          helm upgrade --install $release_name_ingress --repo https://kubernetes.github.io/ingress-nginx ingress-nginx --version=3.7.1 -f ingressvalues.yaml \
            --wait \
            --namespace $namespace

          # install openldap
          helm upgrade --install $openldap_release --repo https://geek-cookbook.github.io/helm-openldap openldap --version 1.2.9 \
            -f test/scripts/ldap-config.yaml \
            --wait \
            --namespace $namespace

          # install Identity Service
          helm dep up helm/alfresco-identity-service
          helm upgrade --install $release_name_ids helm/alfresco-identity-service \
            --set ingress.hostName=$HOST \
            --set realm.alfresco.client.redirectUris[0]="https://${HOST}\*" \
            --set realm.alfresco.client.webOrigins[0]="https://${HOST}\*" \
            --set keycloakx.command[0]="/opt/keycloak/bin/kc.sh" \
            --set keycloakx.command[1]="start" \
            --set keycloakx.command[2]="--import-realm" \
            --set keycloakx.command[3]="--http-relative-path=/auth" \
            --set keycloakx.command[4]="--hostname=${HOST}" \
            --wait \
            --namespace $namespace

          # check dns and pods
          DNS_PROPAGATED=0
          DNS_COUNTER=0
          DNS_COUNTER_MAX=90
          DNS_SLEEP_SECONDS=10

          echo "Trying to perform a trace DNS query to prevent caching"
          dig +trace $HOST @8.8.8.8

          while [ "$DNS_PROPAGATED" -eq 0 ] && [ "$DNS_COUNTER" -le "$DNS_COUNTER_MAX" ]; do
            host $HOST 8.8.8.8
            if [ "$?" -eq 1 ]; then
              DNS_COUNTER=$((DNS_COUNTER + 1))
              echo "DNS Not Propagated - Sleeping $DNS_SLEEP_SECONDS seconds"
              sleep "$DNS_SLEEP_SECONDS"
            else
              echo "DNS Propagated"
              DNS_PROPAGATED=1
            fi
          done

          [ $DNS_PROPAGATED -ne 1 ] && echo "DNS entry for $HOST did not propagate within expected time" && exit 1

          pods_ready

          # Set IDP Config
          ./test/scripts/set_idp_config.sh
          postman_image=postman/newman_alpine33:3.9.2

          # run identity checks
          docker run -a STDOUT --volume $PWD/test/postman:/etc/newman --network host $postman_image run "identity-test-collection.json" --global-var "identity_host=$HOST"
          TEST_RESULT=$?
          echo "TEST_RESULT=${TEST_RESULT}"

          if [[ "${TEST_RESULT}" == "0" ]]; then
            docker run -a STDOUT --volume $PWD/test/postman:/etc/newman --network host $postman_image run "change-keycloak-access-token-lifespan-collection.json" --insecure --global-var "identity_host=$HOST"
            ./test/helm/delete_keycloak_pods.sh
            docker run -a STDOUT --volume $PWD/test/postman:/etc/newman --network host $postman_image run "check-keycloak-access-token-lifespan-change-persisted.json" --insecure --global-var "identity_host=$HOST"
            TEST_RESULT=$?
            echo "TEST_RESULT=${TEST_RESULT}"
          fi

          if [[ "${TEST_RESULT}" == "0" ]]; then
            docker run -a STDOUT --volume $PWD/test/postman:/etc/newman --network host $postman_image run "ldap-user-provider-tests.postman_collection.json" -d "ldap-test-data.json" --global-var "identity_host=$HOST"
            TEST_RESULT=$?
            echo "TEST_RESULT=${TEST_RESULT}"
          fi

          if [[ "${TEST_RESULT}" == "0" ]]; then
            cd test/scripts
            ./auth0-api.sh create $HOST https://$HOST
            ./configure-saml-ids.sh app_name=$HOST ids_base_url=https://$HOST
            cd ../saml
            export KEYCLOAK_HOSTNAME=$HOST
            export KEYCLOAK_ISSUER=https://$HOST/auth/realms/alfresco
            mvn clean test
            TEST_RESULT=$?
            echo "TEST_RESULT=${TEST_RESULT}"
            cd ../..
          fi

          if [[ "${{ github.event.head_commit.message }}" != *"[keep env]"* ]]; then
            helm delete $release_name_ingress $release_name_ids $openldap_release -n $namespace
            kubectl delete namespace $namespace
            cd test/scripts
            ./auth0-api.sh delete $HOST
          fi

          if [[ "${TEST_RESULT}" == "1" ]]; then
            echo "Tests failed, exiting"
            exit 1
          fi
      - name: "Clean up S3 after failure"
        if: ${{ always() && steps.test.outcome == 'failure' }}
        run: aws s3 rm s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/ --recursive

  test_upgrade:
    name: "Test Upgrade"
    runs-on: ubuntu-latest
    needs: build
    if: ${{ !contains(github.event.head_commit.message, '[skip tests]') }}
    steps:
      - uses: actions/checkout@v3
      - uses: Alfresco/alfresco-build-tools/.github/actions/get-build-info@v1.34.2
      - uses: Alfresco/alfresco-build-tools/.github/actions/setup-java-build@v1.34.2
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_PIPELINE_AMPS_ACCESS_KEY_ID  }}
          aws-secret-access-key: ${{ secrets.AWS_S3_PIPELINE_AMPS_SECRET_ACCESS_KEY  }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Prepare test environment"
        run: |
          openssl aes-256-cbc -K ${{ secrets.ENCRYPTED_E69BEC42AE64_KEY }} -iv ${{ secrets.ENCRYPTED_E69BEC42AE64_IV }} -in test/scripts/config-files/realmRsaKeys.json.enc -out test/scripts/config-files/realmRsaKeys.json -d
      - name: "Set IDS_BUILD_NAME"
        run: |
          IDS_BUILD_NAME=$(echo ${BRANCH_NAME} | cut -c1-28 | tr /_ - | tr -d [:punct:] | awk '{print tolower($0)}')-${BUILD_NUMBER}
          echo "IDS_BUILD_NAME=$IDS_BUILD_NAME" >> "$GITHUB_ENV"
          echo $IDS_BUILD_NAME
      - name: "Test"
        id: test
        run: |
          cd test/saml
          mvn clean package -DskipTests
          ./upgrade/test-upgrade.sh
      - name: "Clean up S3 after failure"
        if: ${{ always() && steps.test.outcome == 'failure' }}
        run: aws s3 rm s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/ --recursive

  publish_chart:
    name: "Package and Publish Helm Chart"
    runs-on: ubuntu-latest
    needs: [test_linux, test_windows, test_helm, test_upgrade]
    if: >
      !(failure() || cancelled()) &&
      (github.ref_name == 'master' || contains(github.event.head_commit.message, '[publish]')) &&
      github.event_name != 'pull_request'
    steps:
      - uses: actions/checkout@v3
        with:
          persist-credentials: false
          fetch-depth: 0
      - uses: Alfresco/alfresco-build-tools/.github/actions/get-build-info@v1.34.2
      - uses: Alfresco/alfresco-build-tools/.github/actions/setup-java-build@v1.34.2
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_PIPELINE_AMPS_ACCESS_KEY_ID  }}
          aws-secret-access-key: ${{ secrets.AWS_S3_PIPELINE_AMPS_SECRET_ACCESS_KEY  }}
          aws-region: ${{ env.AWS_REGION }}
      - uses: Alfresco/alfresco-build-tools/.github/actions/configure-git-author@v1.34.2
        with:
          username: ${{ secrets.BOT_GITHUB_USERNAME }}
          email: ${{ secrets.BOT_GITHUB_EMAIL }}
          global: true
      - name: "Set HELM_REPO"
        run: |
          if [[ "${BRANCH_NAME}" == "master" ]] && [[ "${{ github.event.head_commit.message }}" == *"[release]"* ]]
          then
            export HELM_REPO=stable
          fi
          echo "HELM_REPO=$HELM_REPO" >> "$GITHUB_ENV"
          echo $HELM_REPO
      - name: "Publish Helm Chart"
        id: publish
        run: |
          if [[ "${BRANCH_NAME}" != "master" ]]; then
            CHART_VERSION=$(cat helm/${PROJECT_NAME}/Chart.yaml | grep version: | awk '{print $2}')
            # Only modify the chart version if it doesn't have '-M*' at the end
            if [[ "${CHART_VERSION}" != *"-M"* ]]; then
              NON_SUFFIX_VERSION=$(echo "${CHART_VERSION}" | awk -F - '{print $1}')
              ALPHA_BUILD_VERSION="${NON_SUFFIX_VERSION}-A${BUILD_NUMBER}"
              echo "Changing Chart version to ${ALPHA_BUILD_VERSION} as this is a feature branch..."
              sed -i s,$CHART_VERSION,$ALPHA_BUILD_VERSION,g helm/${PROJECT_NAME}/Chart.yaml
            fi
          fi
          COMMIT_MESSAGE_FIRST_LINE=$(git log --pretty=format:%s --max-count=1)
          echo using COMMIT_MESSAGE_FIRST_LINE=${COMMIT_MESSAGE_FIRST_LINE}
          git clone https://${GITHUB_TOKEN}@github.com/Alfresco/charts.git
          echo using HELM_REPO=${HELM_REPO}
          mkdir repo
          helm package --dependency-update --destination repo helm/${PROJECT_NAME}
          helm repo index repo --url ${HELM_REPO_BASE_URL}/${HELM_REPO} --merge charts/${HELM_REPO}/index.yaml
          mv repo/* charts/${HELM_REPO}
          cd charts
          git add ${HELM_REPO}
          git commit -m "${COMMIT_MESSAGE_FIRST_LINE}"
          git push --quiet origin master
      - name: "Clean up S3 after failure"
        if: ${{ always() && steps.publish.outcome == 'failure' }}
        run: aws s3 rm s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/ --recursive

  staging_release:
    name: "Publish to S3 Staging"
    runs-on: ubuntu-latest
    needs: publish_chart
    if: >
      !(failure() || cancelled()) &&
      contains(github.event.head_commit.message, '[staging]') &&
      github.event_name != 'pull_request'
    steps:
      - uses: actions/checkout@v3
      - uses: Alfresco/alfresco-build-tools/.github/actions/get-build-info@v1.34.2
      - uses: Alfresco/alfresco-build-tools/.github/actions/setup-java-build@v1.34.2
      - name: "Set IDENTITY_VERSION"
        run: |
          source distribution/build.properties
          echo "IDENTITY_VERSION=$IDENTITY_VERSION" >> "$GITHUB_ENV"
          echo $IDENTITY_VERSION
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_PIPELINE_AMPS_ACCESS_KEY_ID  }}
          aws-secret-access-key: ${{ secrets.AWS_S3_PIPELINE_AMPS_SECRET_ACCESS_KEY  }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Prepare deploy_dir"
        run: |
          aws s3 cp s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/alfresco-identity-service-${IDENTITY_VERSION}.zip ./deploy_dir/alfresco-identity-service-${IDENTITY_VERSION}.zip
          aws s3 cp s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/alfresco-identity-service-${IDENTITY_VERSION}.md5 ./deploy_dir/alfresco-identity-service-${IDENTITY_VERSION}.md5
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_STAGING_ACCESS_KEY }}
          aws-secret-access-key: ${{ secrets.AWS_S3_STAGING_SECRET_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Publish to S3 Staging"
        id: publish
        run: aws s3 cp --acl private --recursive ./deploy_dir s3://${S3_STAGING_BUCKET}/enterprise/alfresco-identity-service/${IDENTITY_VERSION}
      - uses: aws-actions/configure-aws-credentials@v1
        if: ${{ (always() && steps.publish.outcome == 'failure') || !contains(github.event.head_commit.message, '[release]') }}
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_PIPELINE_AMPS_ACCESS_KEY_ID  }}
          aws-secret-access-key: ${{ secrets.AWS_S3_PIPELINE_AMPS_SECRET_ACCESS_KEY  }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Clean up S3_ARTIFACTS_BUCKET"
        if: ${{ (always() && steps.publish.outcome == 'failure') || !contains(github.event.head_commit.message, '[release]') }}
        run: aws s3 rm s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/ --recursive

  release:
    name: "Publish to S3 and Nexus"
    runs-on: ubuntu-latest
    needs: staging_release
    if: >
      !(failure() || cancelled()) &&
      github.ref_name == 'master' &&
      contains(github.event.head_commit.message, '[release]') &&
      github.event_name != 'pull_request'
    steps:
      - uses: actions/checkout@v3
      - uses: Alfresco/alfresco-build-tools/.github/actions/get-build-info@v1.34.2
      - uses: Alfresco/alfresco-build-tools/.github/actions/setup-java-build@v1.34.2
      - name: "Set IDENTITY_VERSION"
        run: |
          source distribution/build.properties
          echo "IDENTITY_VERSION=$IDENTITY_VERSION" >> "$GITHUB_ENV"
          echo $IDENTITY_VERSION
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_PIPELINE_AMPS_ACCESS_KEY_ID  }}
          aws-secret-access-key: ${{ secrets.AWS_S3_PIPELINE_AMPS_SECRET_ACCESS_KEY  }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Prepare deploy_dir"
        id: prepare
        run: |
          aws s3 cp s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/alfresco-identity-service-${IDENTITY_VERSION}.zip ./deploy_dir/alfresco-identity-service-${IDENTITY_VERSION}.zip
          aws s3 cp s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/alfresco-identity-service-${IDENTITY_VERSION}.md5 ./deploy_dir/alfresco-identity-service-${IDENTITY_VERSION}.md5
          aws s3 rm s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/ --recursive
      - name: "Publish to Nexus"
        run: curl -q -u ${MAVEN_USERNAME}:${MAVEN_PASSWORD} --upload-file ./deploy_dir/alfresco-identity-service-${IDENTITY_VERSION}.zip https://artifacts.alfresco.com/nexus/content/repositories/enterprise-releases/org/alfresco/alfresco-identity-service/${IDENTITY_VERSION}/alfresco-identity-service-${IDENTITY_VERSION}.zip
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_RELEASE_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_S3_RELEASE_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Publish to S3"
        run: aws s3 cp --acl private --recursive ./deploy_dir s3://${S3_RELEASE_BUCKET}/release/enterprise/alfresco-identity-service/${IDENTITY_VERSION}
      - uses: aws-actions/configure-aws-credentials@v1
        if: ${{ (always() && steps.prepare.outcome == 'failure') }}
        with:
          aws-access-key-id: ${{ secrets.AWS_S3_PIPELINE_AMPS_ACCESS_KEY_ID  }}
          aws-secret-access-key: ${{ secrets.AWS_S3_PIPELINE_AMPS_SECRET_ACCESS_KEY  }}
          aws-region: ${{ env.AWS_REGION }}
      - name: "Clean up S3 after failure"
        if: ${{ (always() && steps.prepare.outcome == 'failure') }}
        run: aws s3 rm s3://${S3_ARTIFACTS_BUCKET}/ci-${BUILD_NUMBER}/ --recursive

  release_docker:
    name: "Publish Docker image"
    runs-on: ubuntu-latest
    needs: staging_release
    if: >
      !(failure() || cancelled()) &&
      github.ref_name == 'master' &&
      contains(github.event.head_commit.message, '[release]') &&
      github.event_name != 'pull_request'
    steps:
      - uses: actions/checkout@v3
      - uses: Alfresco/alfresco-build-tools/.github/actions/get-build-info@v1.34.2
      - uses: Alfresco/alfresco-build-tools/.github/actions/setup-java-build@v1.34.2
      - name: "Login to DockerHub Registry"
        uses: docker/login-action@v2.1.0
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}
      - name: "Login to Quay.io Docker Registry"
        uses: docker/login-action@v2.1.0
        with:
          registry: quay.io
          username: ${{ secrets.QUAY_USERNAME }}
          password: ${{ secrets.QUAY_PASSWORD }}
      - name: "Set IDENTITY_VERSION"
        run: |
          source distribution/build.properties
          echo "IDENTITY_VERSION=$IDENTITY_VERSION" >> "$GITHUB_ENV"
          echo $IDENTITY_VERSION
      - name: "Publish Docker image"
        run: |
          export PRIVATE_IMAGE=quay.io/alfresco/alfresco-identity-service:${IDENTITY_VERSION}
          export PUBLIC_IMAGE=alfresco/alfresco-identity-service:${IDENTITY_VERSION}
          docker pull ${PRIVATE_IMAGE}
          docker tag ${PRIVATE_IMAGE} ${PUBLIC_IMAGE}
          docker push ${PUBLIC_IMAGE}
